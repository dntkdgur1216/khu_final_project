import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
# ğŸŒŸ [ë³€ê²½] GradCAM ëŒ€ì‹  EigenCAMì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ViTì— í›¨ì”¬ ê°•ë ¥í•©ë‹ˆë‹¤.
from pytorch_grad_cam import EigenCAM 
from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image
import json
import os

# ì‚¬ìš©ì ë¼ì´ë¸ŒëŸ¬ë¦¬
import utils 
import data_utils

# ==========================================
# 1. ì„¤ì •
# ==========================================
image_path = "data/eurosat/eurosat/2750/Pasture/Pasture_1781.jpg" 
load_dir = "saved_models_remoteclip/eurosat_rgb_cbm_2025_11_23_00_42" 
device = "cuda" if torch.cuda.is_available() else "cpu"

# ==========================================
# 2. ëª¨ë¸ ë¡œë“œ
# ==========================================
args_path = os.path.join(load_dir, "args.txt")
with open(args_path, "r") as f:
    args = json.load(f)

print(f"Loading Backbone: {args['backbone']}...")

if args["backbone"] == 'remote_clip_vit_b_32':
    model, preprocess = utils.load_remote_clip(
        args["clip_name"], 
        args["remote_clip_path"], 
        device
    )
else:
    import clip
    model, preprocess = clip.load(args["clip_name"], device=device)

model.eval()

# ==========================================
# 3. Reshape í•¨ìˆ˜ (ViT í•„ìˆ˜)
# ==========================================
def reshape_transform(tensor):
    if tensor.ndim == 3 and tensor.shape[1] == 1:
         tensor = tensor.permute(1, 0, 2)
    
    # CLS í† í° ì œê±°
    patches = tensor[:, 1:, :] 
    patches = patches.permute(0, 2, 1)
    
    batch, dim, _ = patches.shape
    height = width = int(patches.shape[2] ** 0.5) # 7
    
    return patches.reshape(batch, dim, height, width)

# ==========================================
# 4. EigenCAM ì„¤ì • (â˜…í•µì‹¬ ìˆ˜ì •â˜…)
# ==========================================
# EigenCAMì€ ë§ˆì§€ë§‰ Attention Block ì „ì²´ë¥¼ ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
target_layers = [model.visual.transformer.resblocks[-1]]

# ğŸŒŸ GradCAM -> EigenCAM êµì²´
cam = EigenCAM(model=model.visual, target_layers=target_layers, reshape_transform=reshape_transform)

# ==========================================
# 5. ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì‹¤í–‰
# ==========================================
print(f"Processing image: {image_path}")
rgb_img = cv2.imread(image_path, 1)[:, :, ::-1]

if rgb_img is None:
    raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

# ë¦¬ì‚¬ì´ì§• (224x224)
rgb_img = cv2.resize(rgb_img, (224, 224))
print(f"Resized image shape: {rgb_img.shape}") 

rgb_img_float = np.float32(rgb_img) / 255
input_tensor = preprocess_image(rgb_img_float, 
                                mean=[0.48145466, 0.4578275, 0.40821073], 
                                std=[0.26862954, 0.26130258, 0.27577711]).to(device)

# ì‹¤í–‰
print("Calculating EigenCAM...")
# EigenCAMì€ targetsê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
grayscale_cam = cam(input_tensor=input_tensor)

# ê²°ê³¼ ì‹œê°í™”
grayscale_cam = grayscale_cam[0, :]
visualization = show_cam_on_image(rgb_img_float, grayscale_cam, use_rgb=True)

# ì €ì¥
save_path = "EigenCAM_remoteclip_result.png"
cv2.imwrite(save_path, cv2.cvtColor(visualization, cv2.COLOR_RGB2BGR))
print(f"âœ… Success! Visualization saved to {save_path}")